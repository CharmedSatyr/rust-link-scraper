# Rust Link Scraper

## Description

This command line link scraper takes a valid website URL and returns a list of links on that website. It sends a GET request to each of these links and categorizes them by response status. The program features a colorful interface and robust error handling.

## Instructions

- Make sure Rust is properly configured on your computer. Check [here](https://www.rust-lang.org/tools/install) for installation details. This project was made with rustc 1.38.0.
- Clone this repository and navigate to the `rust-link-scraper` directory in your terminal.
- At the project root, run `cargo run` to install all dependencies, compile the project, and start it.
- Follow the onscreen instructions.
- Please open an issue for any bugs you find.

## Notes

- This project was inspired by the "Extracting Links" projects in the [Rust Cookbook](https://rust-lang-nursery.github.io/rust-cookbook/web/scraping.html) but differs significantly from the provided examples. Check out some of the other recipe ideas if you're new to Rust!
